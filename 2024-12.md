# 12/1
- orphan containersの削除`docker-compose down --remove-orphans`
    孤児コンテナを一括で削除する
- システムテスト bundle exec rspecに成功
    最新のSelenium WebDriverでのCheomeのオプション設定がよくなかったらしい

# 12/2
  - システムテストを追加
    - ログイン機能
    - 新規登録機能（途中）
      メモリ不足でクラッシュしてしまうので、分割でテスト`bundle exec rspec spec/system/users_spec.rb:テストしたい行`
    - レビュー修正
      - google maps表示
        - マップが表示されない
          => Google CloudのAPIとサービス>認証情報>ウェブサイトの制限でURL固定としていた。*をつけて修正。
        - 一度更新しないとマップが表示されない
          => Google Maps APIの初期化がページの完全なロードを必要とするが、`turbo:load`だとgoogle.mapsの読み込みが完了しているかわからない。また、Google Maps APIスクリプトの読み込みを非同期`async, defer`で行っていてJavascriptのコードがgoole.mapsのロードよりも先に実行される可能性がある。Google Maps APIオード完了後に初期化するようにロード後に呼び出す関数を設定`window.initMapCallback = callback;`
      - LINEログイン
        コールバックURLが今まででproduction側した反応していなかった？developmentのみにしたら`GET "/oauth/line"`時点で400エラーに

# 12/3

# 12/4
  - 画像をアップロードするとエラー`Permission denied @ dir_s_mkdir - /rails/public/uploads/tmp`
    [参考【AWSのS3で本番環境でも画像を保存できるようにしよう】](https://qiita.com/iijima-naoya-45b/items/0bdf75bde960787c9c04)
    - AWSにルートユーザーでログイン
    - バケット(自分のデータを保存する場所)の作成
      S3を検索>バケットを作成
      - バケット名
      - AWSリージョン：アジアパシフィック
      - アクセス設定
        - 新しいパブリックバケットポリシーまたはアクセスポイントポリシーを介して付与されたバケットとオブジェクトへのパブリックアクセスをブロックする
        - 任意のパブリックバケットポリシーまたはアクセスポイントポリシーを介したバケットとオブジェクトへのパブリックアクセスとクロスアカウントアクセスをブロックする
        - 現在の設定により、このバケットとバケット内のオブジェクトが公開される可能性があることを承認します。
        
        をチェック
        =>バケットを作成
    - IAMユーザーの情報取得
      IAM>ユーザーの作成>ユーザー名を入力して次へ>許可のオプション：ポリシーを直接
      アタッチする>許可ポリシーでAmazonS3FullAccessにチェックし次へ>ユーザーの作成
      ARN: ---
      作成したユーザーを選択>セキュリティ認証情報>アクセスキーを作成＞作成
        アクセスキー: ---
        シークレットアクセスキー: ---
    - バケットポリシー(バケットに対して、どのユーザーがどの処理をできるの取り決め)
の設定
      IAMユーザーのみバケットにアクセスできるよう設定
      S3>作成したバケット名>アクセス許可>パケットポリシー>編集
      ```
      {
        "Version": "2012-10-17",
        "Id": "Policy1544152951996",
        "Statement": [
            {
                "Sid": "Stmt1544152948221",
                "Effect": "Allow",
                "Principal": {
                    "AWS": "取得したIAMユーザーのARN"
                },
                "Action": "s3:*",
                "Resource": "arn:aws:s3:::バケット名"
            }
        ]
      }
      ```

  - `gem aws-sdk-s3`を取得
    Gemfileに`gem "aws-sdk-s3", require: false`を追加>bundle install
  - 画像の保存先をlocalからS3に保存されるように設定を変更 
    ```
    # development.rb
    #config.active_storage.service = :local
    config.active_storage.service = :amazon

    # production.rb
    #config.active_storage.service = :local
    config.active_storage.service = :amazon
    ```

  - storage.ymlファイルの編集、環境変数の仕様
    ```
    # config/storage.yml
    amazon:
      service: S3
      access_key_id: <%= ENV['AWS_ACCESS_KEY_ID'] %>  
      secret_access_key: <%= ENV['AWS_SECRET_ACCESS_KEY'] %>
      region: ap-southeast-2
      bucket: <%= ENV['AWS_BUCKET_NAME'] %> 

    # .env
    AWS_ACCESS_KEY_ID="発行したアクセスキー"
    AWS_SECRET_ACCESS_KEY="シークレットキー"
    AWS_BUCKET_NAME="バケット名"
    ```

  - `gem fog-aws`を取得
    Gemfileに`gem "fog-aws"`を追加>bundle install
  - アップローダーの編集
    ```
    # uploaders/book_image_uploader.rb
    class BookImageUploader < CarrierWave::Uploader::Base
      # Include RMagick or MiniMagick support:
      # include CarrierWave::RMagick
      # include CarrierWave::MiniMagick

      # Choose what kind of storage to use for this uploader:
      # storage :file
      storage :fog
      # if Rails.env.production?
      #   storage :fog # 本番環境ではfogを使用
      # else
      #   storage :file # 開発環境とテスト環境ではfileを使用
      # end

      # Override the directory where uploaded files will be stored.
      # This is a sensible default for uploaders that are meant to be mounted:
      def store_dir
        "uploads/#{model.class.to_s.underscore}/#{mounted_as}/#{model.id}"
      end

      # Provide a default URL as a default if there hasn't been a file uploaded:
      def default_url
        ActionController::Base.helpers.asset_path("book_image.png")
      end

      # Process files as they are uploaded:
      # process scale: [200, 300]
      #
      # def scale(width, height)
      #   # do something
      # end

      # Create different versions of your uploaded files:
      # version :thumb do
      #   process resize_to_fit: [50, 50]
      # end

      # Add an allowlist of extensions which are allowed to be uploaded.
      # For images you might use something like this:
      def extension_allowlist
        %w[jpg jpeg gif png]
      end

      # Override the filename of the uploaded files:
      # Avoid using model.id or version_name here, see uploader/store.rb for details.
      # def filename
      #   "something.jpg"
      # end
    end
    ```
  - carriewave.rbの編集
    ```
    require 'carrierwave/storage/abstract'
    require 'carrierwave/storage/file'
    require 'carrierwave/storage/fog'

    CarrierWave.configure do |config|
        config.storage :fog
        config.fog_provider = 'fog/aws'
        config.fog_directory  = 'watashi-no-shiori' # バケット名
        config.fog_credentials = {
          provider: 'AWS',
          aws_access_key_id: ENV['AWS_ACCESS_KEY_ID'], # 環境変数
          aws_secret_access_key: ENV['AWS_SECRET_ACCESS_KEY'], # 環境変数
          region: 'ap-southeast-2', # リージョン
          path_style: true
        }
    end 
    ```

  -  開発環境で確認
    - 再起動してdocker compose upをすると、
      ```
      web-1              | Bundle complete! 33 Gemfile dependencies, 168 gems now installed.
      web-1              | Use `bundle info [gemname]` to see where a bundled gem is installed.
      web-1              | 1 installed gem you directly depend on is looking for funding.
      web-1              |   Run `bundle fund` for details
      web-1              | bin/rails aborted!
      web-1              | NoMethodError: private method `warn' called for ActiveSupport::Deprecation:Class (NoMethodError)
      web-1              |
      web-1              |   ActiveSupport::Deprecation.warn("Some deprecation message")
      web-1              |                             ^^^^^
      web-1              | /myapp/config/initializers/carriewave.rb:17:in `block in <main>'
      web-1              | /myapp/config/initializers/carriewave.rb:5:in `<main>'
      web-1              | /myapp/config/environment.rb:5:in `<main>'
      web-1              | Tasks: TOP => db:prepare => db:load_config => environment
      web-1              | (See full trace by running task with --trace)
      web-1 exited with code 1
      ```
      でdbが作成されず、？？？
      [参考サイト](https://zenn.dev/mockey/articles/daf80384bf18d2)のエラー報告をもとに`carriewave.rb`を編集
      ```
      require 'carrierwave/storage/abstract'
      require 'carrierwave/storage/file'
      require 'carrierwave/storage/fog'

      CarrierWave.configure do |config|
        config.storage :fog
      #   config.fog_provider = 'fog/aws'
        config.fog_directory  = 'watashi-no-shiori' # バケット名
        config.fog_credentials = {
            provider: 'AWS',
            aws_access_key_id: ENV['AWS_ACCESS_KEY_ID'], # 環境変数
            aws_secret_access_key: ENV['AWS_SECRET_ACCESS_KEY'], # 環境変数
            region: 'ap-southeast-2', # リージョン
          #   path_style: true
        }
      end
      ```
      無事docker compose upできた
    - しおり作成でエラー`Excon::Error::BadRequest in BooksController#create`
      エラーを読んでいくとAccessControlListNotSupportedというエラーが発生していた。
      AWS S3バケットに対してアクセスコントロールリスト(ACL)が許可されていないためリクエストが拒否されている。
      AWSでS3>使用するバケットを選択>アクセス許可>オブジェクト所有者>ACL有効に変更しエラー解消
  - production環境を設定
    >RenderでEnvironment>Secret FilesでFilename: .env、Contents: VScodeで.envに追加した部分を入力>保存
    =>SecretFilesだとなぜかデプロイ失敗する。Environment Variablesにそれぞれ追加しデプロイ成功。

# 12/5
- LINEログインができない
  前の修正のまま進められた。コールバックするときにngrokのアドレスを修正せず行ったためエラー？(LINE Developersなのか、sorcery.rbの変更に時間がかかる？)
  一度時間をおいて再度試行。=>docker再起動したら問題なかった
  LINEでログインしてコールバックしたときに必要な権限が持ってこれていなそう
  `OAuth2::Error {"message":"user doesn't grant required permissions yet"}`
  scopeにprofileを追加し、emailにdisplayNameを入れることで解消したが、これはどうなんだ？今後検討したいところ
- デプロイ環境で画像アップロードが`Excon::Error::Forbidden (Expected(200) <=> Actual(403 Forbidden) AccessDenied</Code><Message>User: arn:aws:iam::872515295999:user/Suzuki is not authorized to perform: s3:GetObject on resource:`
  [参考](https://qiita.com/siruku6/items/a3a9021913749247d92b)より、`donfig.fog_pulic`の設定をしていないと403エラーになりそう

  User: arn:aws:iam::872515295999:user/Suzuki is not authorized to perform: s3:GetObject with an explicit deny in an identity-based policy
  > ほとんどのアクセス拒否のエラーメッセージは、User user-arn is not authorized to perform action on "resource-arn" because context の形式です。この例では、user-arn は、アクセス権がないユーザーの Amazon リソースネーム (ARN)、action はポリシーが拒否するサービスアクション、resource-arn はポリシーが対象とするリソースの ARN です。context フィールドには、ポリシータイプについての追加のコンテキストが表示され、ポリシーがアクセスを拒否した理由が説明されます。
  > ポリシー内の Deny ステートメントで明示的にポリシーがアクセスを拒否した場合、アクセス拒否エラーメッセージには、with an explicit deny in a type policy というフレーズが含まれます。ポリシーがアクセスを暗黙的に拒否する場合、アクセス拒否エラーメッセージには、because no type policy allows the action action というフレーズが含まれます。

  `an identity-based`で明示的にポリシーがアクセスを拒否している
  > ID ベースのポリシーによるアクセスの拒否 – 明示的拒否
ID にアタッチされた ID ベースのポリシーにあるアクションに対して、明示的な Deny ステートメントがあるのかを確認してください。次の例のアクションは、ユーザー MaryMajor にアタッチされた s3:GetObject です。
  > Deny ステートメントを変更してポリシーを更新し、ユーザーに必要なアクセスを許可します。例えば、「IAM ユーザーガイド」の aws:PrincipalAccount に示すように、aws:PrincipalAccount 条件キーと StringNotEquals 条件演算子を使用して、特定のプリンシパルアクセスを許可するように Deny ステートメントを更新できます。詳細については、「IAM ユーザーガイド」の「アイデンティティベースのポリシー」と「IAM ポリシーの編集」を参照してください。

  S3のバケットポリシーに`"Condition": {"StringEquals": {"aws:PrincipalAccount": "872515295999"}}`を追加したがエラーは変わらず。
  質問フォームで講師の方に見てもらうことに。
  issue: https://github.com/aio97/graduate_app/issues/

# 12/6
- デプロイ環境での画像アップロード機能ーS3を導入
  ひとまず、AWSのアクセスキーとシークレットアクセスキーをGithubにのせてしまったぽいので無効化し、再度アクセスキーを作成
  issueの返信でなかい講師から
  > S3の設定を確認する前に、技術記事を参考にしてる人で設定内容が公式と違うためエラーが出ている人が何人かいるので、Carrierwaveの公式サイトを確認して設定項目に何を設定すればいいのかの再度確認をお願いします。(providerの設定とかが違ったと思います)
  > またgemのバージョン指定も公式のものとあっているか確認してください
  > https://github.com/carrierwaveuploader/carrierwave?tab=readme-ov-file#fog
  
  とご連絡いただいた。
  Githubで使いそうなところ
    ### Changing the storage directory
    In order to change where uploaded files are put, just override the store_dir method:
    ```
    class MyUploader < CarrierWave::Uploader::Base
      def store_dir
        'public/my/upload/directory'
      end
    end
    ```

    This works for the file storage as well as Amazon S3 and Rackspace Cloud Files. Define store_dir as nil if you'd like to store files at the root level.

    If you store files outside the project root folder, you may want to define cache_dir in the same way:
    ```
    class MyUploader < CarrierWave::Uploader::Base
      def cache_dir
        '/tmp/projectname-cache'
      end
    end
    ```

    ### Using Amazon S3
    Fog AWS is used to support Amazon S3. Ensure you have it in your Gemfile:
    ```
    gem "fog-aws"
    ```

    You'll need to provide your fog_credentials and a fog_directory (also known as a bucket) in an initializer. For the sake of performance it is assumed that the directory already exists, so please create it if it needs to be. You can also pass in additional options, as documented fully in lib/carrierwave/storage/fog.rb. Here's a full example:
    ```
    CarrierWave.configure do |config|
      config.fog_credentials = {
        provider:              'AWS',                        # required
        aws_access_key_id:     'xxx',                        # required unless using use_iam_profile
        aws_secret_access_key: 'yyy',                        # required unless using use_iam_profile
        use_iam_profile:       true,                         # optional, defaults to false
        region:                'eu-west-1',                  # optional, defaults to 'us-east-1'
        host:                  's3.example.com',             # optional, defaults to nil
        endpoint:              'https://s3.example.com:8080' # optional, defaults to nil
      }
      config.fog_directory  = 'name_of_bucket'                                      # required
      config.fog_public     = false                                                 # optional, defaults to true
      config.fog_attributes = { cache_control: "public, max-age=#{365.days.to_i}" } # optional, defaults to {}
      # Use this if you have AWS S3 ACLs disabled.
      # config.fog_attributes = { 'x-amz-acl' => 'bucket-owner-full-control' }
      # Use this if you have Google Cloud Storage uniform bucket-level access enabled.
      # config.fog_attributes = { uniform: true }
      # For an application which utilizes multiple servers but does not need caches persisted across requests,
      # uncomment the line :file instead of the default :storage.  Otherwise, it will use AWS as the temp cache store.
      # config.cache_storage = :file
    end
    ```

    In your uploader, set the storage to :fog
    ```
    class AvatarUploader < CarrierWave::Uploader::Base
      storage :fog
    end
    ```

    That's it! You can still use the CarrierWave::Uploader#url method to return the url to the file on Amazon S3.

    Note: for Carrierwave to work properly it needs credentials with the following permissions:

    s3:ListBucket
    s3:PutObject
    s3:GetObject
    s3:DeleteObject
    s3:PutObjectAcl`CarrierWave` の設定例として提供されているこのコードの各部分を分かりやすく説明します。この設定は、AWS S3をストレージとして利用する場合の例です。

    chat GPTの説明
    ### **基本構造**
    ```ruby
    CarrierWave.configure do |config|
      config.fog_credentials = { ... }  # AWSの接続情報
      config.fog_directory  = 'name_of_bucket' # バケット名
      config.fog_public     = false           # 公開設定
      config.fog_attributes = { ... }         # 追加属性
    end
    ```

    - **`CarrierWave.configure`**: CarrierWaveの設定を指定します。
    - **`config.fog_credentials`**: AWS S3に接続するための認証情報を指定します。
    - **`config.fog_directory`**: 保存先のS3バケット名を指定します。
    - **`config.fog_public`**: アップロードしたファイルを公開するかどうかを指定します。
    - **`config.fog_attributes`**: S3にアップロードする際に追加する設定を指定します。

    ---

    ### **各項目の説明**
    #### **`config.fog_credentials`**
    AWS S3への接続に必要な情報を指定します。

    ```ruby
    provider: 'AWS'
    ```
    - 使用するクラウドサービスプロバイダーを指定します。ここではAWSを指定。

    ```ruby
    aws_access_key_id: 'xxx'
    aws_secret_access_key: 'yyy'
    ```
    - AWSのアクセスキーとシークレットキーを指定します。
    - もしIAMロールを使用している場合（`use_iam_profile: true`の場合）は省略できます。

    ```ruby
    use_iam_profile: true
    ```
    - AWSのIAMロールを使用する場合に`true`を指定します。
    - 本番環境ではセキュリティのためにIAMロールの使用を推奨します。

    ```ruby
    region: 'eu-west-1'
    ```
    - S3バケットが存在するリージョンを指定します。
      - 例: 東京リージョンの場合は `'ap-northeast-1'`

    ```ruby
    host: 's3.example.com'
    endpoint: 'https://s3.example.com:8080'
    ```
    - 独自のS3互換ストレージを使用する場合に指定します（通常AWSでは必要ありません）。

    ---

    #### **`config.fog_directory`**
    ```ruby
    config.fog_directory = 'name_of_bucket'
    ```
    - ファイルをアップロードするS3のバケット名を指定します。

    ---

    #### **`config.fog_public`**
    ```ruby
    config.fog_public = false
    ```
    - アップロードしたファイルを公開するかどうかを設定します。
      - `true`: 誰でもアクセス可能。
      - `false`: 非公開。認証が必要になります。

    ---

    #### **`config.fog_attributes`**
    ```ruby
    config.fog_attributes = { cache_control: "public, max-age=#{365.days.to_i}" }
    ```
    - S3に保存するファイルに追加するHTTPヘッダーを指定します。
    - この例では、ブラウザにキャッシュを365日間保持させる指示を出します。
      - `cache_control: "public, max-age=31536000"`: キャッシュの最大保存期間を1年に設定。

    ---

    ### **コメントされている部分**
    #### **キャッシュストレージの設定**
    ```ruby
    # config.cache_storage = :file
    ```
    - デフォルトではS3をキャッシュストレージとして使用します。
    - 複数のサーバー間でキャッシュを共有する必要がない場合、`:file`にするとローカルディスクを使用します。

    #### **AWS S3 ACLsが無効な場合**
    ```ruby
    # config.fog_attributes = { 'x-amz-acl' => 'bucket-owner-full-control' }
    ```
    - AWS S3 ACL（アクセスコントロールリスト）が無効になっている場合に、この設定を追加すると所有者がフルアクセスを持てるようになります。

    #### **Google Cloud Storageの場合**
    ```ruby
    # config.fog_attributes = { uniform: true }
    ```
    - GCS（Google Cloud Storage）を使う場合の設定例。

    ---

    ### **本番環境での重要なポイント**
    1. **`use_iam_profile` の有効化**  
      本番環境では`use_iam_profile: true`を利用することで、環境変数やハードコードしたキーを使用せずにIAMロールを通じてアクセスする方法が推奨されます。

    2. **`config.fog_public` の設定**  
      ファイルを非公開にする場合、`false`を指定してください。非公開のファイルを扱う際はアプリケーション側で署名付きURLを生成する必要があります。

    3. **リージョンの正確な指定**  
      自分のバケットが存在するAWSリージョンを正しく指定してください。

    4. **バケットポリシーとの整合性**  
      S3バケットのポリシーがCarrierWaveの設定に合っているかを確認してください。

    ---

    これを踏まえて設定しなおした。
```ruby
# carrierwave.rb
require "carrierwave/storage/abstract"
require "carrierwave/storage/file"
require "carrierwave/storage/fog"

CarrierWave.configure do |config|
  config.fog_credentials = {
    provider:              "AWS",
    aws_access_key_id:     ENV["AWS_ACCESS_KEY_ID"],
    aws_secret_access_key: ENV["AWS_SECRET_ACCESS_KEY"],
    region:                "ap-southeast-2",
  }
  config.fog_directory  = "watashi-no-shiori"
  config.fog_public     = false
  config.fog_attributes = { cache_control: "public, max-age=#{365.days.to_i}" }
end

# バケットポリシー
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "AllowSuzukiAccess",
            "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:iam::872515295999:user/Suzuki"
            },
            "Action": "s3:*",
            "Resource": [
                "arn:aws:s3:::watashi-no-shiori",
                "arn:aws:s3:::watashi-no-shiori/*"
            ]
        }
    ]
}

# S3 オブジェクト所有者>ACL無効
```

開発環境で試行
ログではエラーが出ずredirectされるが画像は表示されない
検証ツール>ネットワークでみると画像ファイルに`（失敗）net::ERR_BLOCKED_BY_ORB`と表示あり。

# 12/7
- AWSからGithubにアクセスキーが出たことによる制限のメールが来てた
  =>対応済。これで保存できなかった可能性あるかも

# 12/8

# 12/9
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "AllowSuzukiAccess",
            "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:iam::872515295999:user/Suzuki"
            },
            "Action": [
                "s3:ListBucket",
                "s3:PutObject",
                "s3:GetObject",
                "s3:DeleteObject",
                "s3:PutObjectAcl"
            ],
            "Resource": [
                "arn:aws:s3:::watashi-no-shiori",
                "arn:aws:s3:::watashi-no-shiori/*"
            ]
        }
    ]
}

# 12/10

# 12/11
- 追加質問のフォームを送信（issueにコメントじゃなかった、、、）

# 12/12
- 返信いただいて確認事項
  [ ] carriewave.rbのregion
  > また、一旦権限を弱めて誰でもオブジェクトのアップロード・読み込みが出来る状態にしてS3の権限周りの設定に何か問題があるのか、CarrierwaveやRails側での設定に何かおかしなところがあるか探ってみるとよいと思います
    



# todo
  本リリース後
  [ ] システムテストを追加
  [ ] 管理画面（ユーザー、しおりを管理）
  [ ] モデルテスト（関連モデル）を追加
      - Userモデル
        関連テスト:
        has_many :booksが正しく関連付けられているか確認するテスト
        has_many :bookmarks（もしあれば）も確認するテスト
      - Bookモデル
        関連テスト:
        belongs_to :userが正しく関連付けられているか確認するテスト
        belongs_to :planが正しく関連付けられているか確認するテスト
      - Planモデル
        バリデーションテスト:
        start_time, end_time, titleが存在することを確認するテスト
        location, detail, memoが空でも許可されることを確認するテスト
        関連テスト:
        has_many :booksが正しく関連付けられているか確認するテスト
  [ ] プランのカラム追加
  [ ] ルート検索機能
  [ ] アルバム機能
  [ ] 割り勘機能

# 学びメモ

  システムテスト
    ユーザー認証
      未ログイン状態でのアクセス:
      トップページが表示されることを確認するテスト
      しおり一覧が表示されることを確認するテスト
      しおり作成やブックマークのリンクが非表示であることを確認するテスト
    ログイン後の機能

しおり作成:

ログイン後、しおり作成ページに遷移できることを確認するテスト
必要なフィールドを満たしてしおりが作成できることを確認するテスト
不足しているフィールドの場合、エラーメッセージが表示されることを確認するテスト
ブックマーク機能:

他のユーザーの書籍をブックマークできることを確認するテスト
自分の書籍をブックマークできないことを確認するテスト
しおり一覧表示

しおりが正しく表示されるか:
作成したしおりが一覧に表示されることを確認するテスト

アドバイス
テストを小さく保つ: 各テストは単一の機能に焦点を当て、テストの目的を明確にすることが重要だカ。
テストデータの準備: FactoryBotを使ってテストデータを準備すると、テストが簡潔になり、可読性も向上するぞ。
エラーメッセージの検証: ユーザーが何かを間違えたときに表示されるエラーメッセージもテストして、ユーザー体験を確認することが大事だナ。
